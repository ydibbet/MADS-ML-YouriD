{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Python\n",
    "This notebook is intended to make a quick scan of different skills. It will test:\n",
    "\n",
    "- knowledge about mathematical notation (function definitions, sets) and a minimum of linear algebra (matrix multiplication)\n",
    "- numpy (generating data, concatenating, dotproduct)\n",
    "- generate a pandas dataframe, basic plotting\n",
    "- creating a class\n",
    "- basic efficiency (avoiding forloops with vectorization)\n",
    "- list comprehensions\n",
    "\n",
    "Don't worry if you get stuck: this notebook is meant to identify the subjects where you will need more explanation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 1\n",
    "### definition 1\n",
    ">Let there be $m$ observations $x_i \\in X$ with $i=\\{1, ..., m\\}$ where every observation has $n$ features: $x_i=\\{x_{i,1}, ..., x_{i,n}\\}$ \n",
    "\n",
    "We will represent these as a matrix $X$ with dimensions $(m, n)$ such that value $x_{i,j}$ is the $i^{th}$ observation for feature $j$.\n",
    "\n",
    "### objective\n",
    "\n",
    "Use numpy to create a matrix $X$ with $m=100, n=2$, filled with random floating point numbers. This will be our set of 100 observations with 2 features.\n",
    "\n",
    "<details>\n",
    "  <summary>HINT: Click to expand!</summary>\n",
    "\n",
    "  You can use `np.random.rand`\n",
    "  If you are not familiar, you can access the documentation directly from the jupyter notebook, by running either\n",
    "  `help(np.random.rand)` or `?np.random.rand`\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.rand(100,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 2\n",
    "\n",
    "### definition 2\n",
    ">We want to implement a function $f: \\mathbb{R}^m \\to \\mathbb{R}$ such that $$f(x) = wx + b$$\n",
    ">Here, $w$ are weights $w=\\{w_1, ..., w_n\\}$ where $n$ corresponds to the number of features and $b$ is an extra bias weight. We will initialize $w$ at random.\n",
    "\n",
    "\n",
    "**Example** if we observe a person $x_1$, as features let us measure someones height and shoe-size. Let us obtain $x_1=\\{1.84, 46\\}$.\n",
    "Now, let our randomly initialized weights $w$ be $\\{0.9, 0.2\\}$ and our $b=3$. With this, we would need to calculate: $0.9 * 1.84 + 0.2 * 46 + 3$ for that person.\n",
    "For a next person let us obtain $x_2=\\{1.65, 36\\}$, and thus we would need to calculate $0.9 * 1.65 + 0.2 * 36 + 3$.\n",
    "\n",
    "### definition 3\n",
    "To implement this more efficient, we will redefine the function slightly:\n",
    ">First, we add a dummy observation of 1 to the features: we get $x_i=\\{x_{i,1}, ..., x_{i,n}, 1\\}$\n",
    ">Then, we add the bias to the weights, such that we get $w=\\{w_1, ..., w_n, b\\}$.\n",
    ">With this, we can change the formula to $$f(x)= wx$$\n",
    "\n",
    "\n",
    "**Example** our previous example would be $x_1=\\{1.84, 46, 1\\}$ and $w=\\{0.9, 0.2, 3\\}$ and we would calculate $0.9 * 1.84 + 0.2 * 46 + 3 * 1$.\n",
    "\n",
    "### Objective\n",
    "To implement this , do the following:\n",
    "- create a columnvector $Xb$ where all entries are equal to 1, with dimensions $(m, 1)$. This will be the weight used for the bias. Do not hardcode $m$, but retrieve it from $X$.\n",
    "- concatenate the observations $X$ with $Xb$ along the columns, such that you get a matrix with dimensions $(m, n+1)$.\n",
    "- initialize a columnvector $w$ where you add the bias as one of the weights. So, it should have dimensions $(n+1, 1)$. Do not hardcode $n$, but retrieve it from $X$.\n",
    "- calculate $f(x)$ for all $m$\n",
    "- store the result of your calculation, that should have shape $(m, 1)$ in a variable `yhat`, which refers to your prediction $\\hat{y}$ \n",
    "\n",
    "<details>\n",
    "  <summary>HINT: Click to expand!</summary>\n",
    "  \n",
    "  For this, you can use the following numpy functions:\n",
    "  `np.ones`, `np.concatenate`, `np.random.rand` and `np.dot`.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xb = np.ones((len(X), 1))\n",
    "X = np.concatenate([X, Xb], axis=1)\n",
    "W = np.random.rand(X.shape[-1],1)\n",
    "yhat = np.dot(X, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 3\n",
    "\n",
    "### Objective\n",
    "- concatenate $X$ and your prediction `yhat`\n",
    "- put them in a pandas dataframe, with column names 'height', 'shoe', 'bias' and 'yhat'.\n",
    "- make a scatterplot, with on the x-axis 'height', on the y-axis 'shoe', and use 'yhat' as a color.\n",
    "\n",
    "Make sure you have:\n",
    "- labels 'height' and 'shoe' on the x and y axis\n",
    "- a legend for the color\n",
    "- a title 'prediction'\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>HINT: Click to expand!</summary>\n",
    "\n",
    "  For this excercise, you can use `np.concatenate`, `pd.DataFrame`, `sns.scatterplot` and `plt.title`.\n",
    "  Alternatively, you can completely use matplotlib `plt.scatter` or `plt.plot` for plotting, but getting the colors right will take much more coding then the sns.scatterplot oneliner.\n",
    "  \n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate([X, yhat], axis=1)\n",
    "p = pd.DataFrame(data, columns=['length', 'shoe', 'bias', 'yhat'])\n",
    "sns.scatterplot(data=p, x='length', y='shoe', hue='yhat')\n",
    "plt.title('prediction')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 4\n",
    "\n",
    "### Objective\n",
    "Create a class `LinearFunction` with three functions: `__init__`, `generate` and `predict`:\n",
    "\n",
    "*\\_\\_init__*\n",
    "- on initialization you pass variables $m$ and $n$, corresponding to $m$ observations with $n$ features.\n",
    "- store the original $(m,n)$ dimensions as a tuple in the object\n",
    "- you call the `generate` function\n",
    "\n",
    "*generate*\n",
    "- initialize random data using variables $n$ and $m$, add a column for the bias, \n",
    "- generate weights\n",
    "- store data and weights in the object\n",
    "\n",
    "*predict*\n",
    "- you return the result of $f(x)=wx+b$\n",
    "\n",
    "\n",
    "<details>\n",
    "  <summary>HINT: Click to expand!</summary>\n",
    "\n",
    "  This is mainly stitching together the previous lines of code into functions and a class.\n",
    "  So just reuse what you did before, and make sure everything works inside a function.\n",
    "  \n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearFunction():\n",
    "    def __init__(self, m : int, n: int):\n",
    "        self.shape = (m, n)\n",
    "        self.generate()\n",
    "\n",
    "    def generate(self):\n",
    "        X = np.random.rand(self.shape[0],self.shape[1])\n",
    "        Xb = np.ones((len(X), 1))\n",
    "        self.X = np.concatenate([X, Xb], axis=1)\n",
    "        self.W = np.random.rand(self.X.shape[-1],1)\n",
    "\n",
    "    def predict(self):\n",
    "        return np.dot(self.X, self.W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 5\n",
    "If you have implemented your formula efficiently, you should be able to scale it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "small = LinearFunction(1000, 3)\n",
    "yhat = small.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function should run in seconds. On my laptop ((2.4 GHz Quad-Core Intel i5), I runs in 1.7 seconds.\n",
    "If it takes much longer, you didnt implement it efficiently and should go back to the implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "big = LinearFunction(100000, 1000)\n",
    "yhat = big.predict()\n",
    "len(yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code will test this solution for linear growing numbers (factor 10) of observations and features.\n",
    "The time it takes to compute should not grow with a factor 10, but slower.\n",
    "If the previous code did not run fast (eg around 2 seconds, but definitely below 10 sec) you should either fix that, or reduce the maximum numbers in the ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrange = range(2,5)\n",
    "mrange = range(1,4)\n",
    "heatmap_vec = np.zeros((len(nrange),len(mrange)))\n",
    "\n",
    "for i, n in enumerate([10**i for i in nrange]):\n",
    "    for j, m in enumerate([10**i for i in mrange]):\n",
    "        func = LinearFunction(n, m)\n",
    "        looptime = %timeit -o func.predict()\n",
    "        heatmap_vec[i, j] = looptime.average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(heatmap_vec, annot=heatmap_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Excercise 6\n",
    "Define a variable `threshold=1`.\n",
    "Create a list comprehension that runs through the yhat, and assigns a value -1 for every value smaller then the threshold, else 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 1\n",
    "\n",
    "clf = [-1 if x < threshold else 1 for x in yhat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list comprehension that will select every item in X, if it is larger than\n",
    "2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 2, 3, 4, 5]\n",
    "select = [x for x in X if x > 2]\n",
    "assert select == [3,4,5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list comprehension that has the same result as this nested forloop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = [\"a\", \"b\", \"c\"]\n",
    "\n",
    "out = []\n",
    "for x in X:\n",
    "    for z in Z:\n",
    "        out.append(str(x) + z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = [str(x) + z for x in X for z in Z]\n",
    "assert out == out2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a list comprehension that both unpacks the values in the dictionary AND\n",
    "inverts the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nested_data = {\"a\" : [1,2,3],\n",
    "               \"b\" : [10, 20, 30]}\n",
    "\n",
    "new_dict = {}\n",
    "for k,values in nested_data.items():\n",
    "    for v in values:\n",
    "        new_dict[v] = k\n",
    "new_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict2 = {v:k for k, values in nested_data.items() for v in values}\n",
    "assert new_dict == new_dict2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit ('3.9.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "c42a0a2900956ab7a89ede89f2c46c7e488ca7435c057b96fa71de27f73f979b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
