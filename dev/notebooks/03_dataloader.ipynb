{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Build a custom dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generators in this notebook (e.g. using the `yield` keyword) are explained in notebook `02_datagenerators.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import Iterator, Tuple, List\n",
    "import mads_datasets\n",
    "mads_datasets.__version__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with images is that the size grows pretty fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (180, 180, 3)\n",
    "\n",
    "for i in [1, 10, 100]:\n",
    "    size = (i, ) + image_size\n",
    "    X = np.zeros(size)\n",
    "    size_byte = X.nbytes\n",
    "    print(f\"Size for {i} images: {size_byte / (2**20)} MB\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine what would happen if you actually have a million images! And no, the answer to this\n",
    "is not \"just get more RAM in the cloud\". You actually don't need to store everything at\n",
    "the same time in memory, right? So we will use the dataloader pattern to fix this problem. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow has a nice [collection of datasets](https://www.tensorflow.org/datasets) for machine learning tasks. Let's download the 'flower_photos' dataset. We will use that dataset for image classification later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets import DatasetFactoryProvider, DatasetType\n",
    "flowersfactory = DatasetFactoryProvider.create_factory(DatasetType.FLOWERS)\n",
    "flowersfactory.download_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = flowersfactory.subfolder\n",
    "print(image_folder)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's  build a datagenerator from scratch; even though there are a lot of libraries (tensorflow, pytorch, trax) that provide datagenerators for images, it is a usefull practice to learn how the inside works. \n",
    "\n",
    "Eventually you will encounter a task were you will need to read in data from disk, and it is always usefull if you know how to adapt to a custom case. First step is to list all files in the directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_dir(path: Path) -> Iterator:\n",
    "    \"\"\"loops recursively through a folder\n",
    "\n",
    "    Args:\n",
    "        path (Path): folder to loop trough. If a directory\n",
    "            is encountered, loop through that recursively.\n",
    "\n",
    "    Yields:\n",
    "        Generator: all paths in a folder and subdirs.\n",
    "    \"\"\"\n",
    "\n",
    "    for p in Path(path).iterdir():\n",
    "        if p.is_dir():\n",
    "            yield from walk_dir(p)\n",
    "            continue\n",
    "        # resolve works like .absolute(), but it removes the \"../..\" parts\n",
    "        # of the location, so it is cleaner\n",
    "        yield p.resolve()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the first file is a .txt file, so we will need to filter that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = walk_dir(image_folder)\n",
    "file1 = next(paths)\n",
    "file2 = next(paths)\n",
    "file1, file2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we now have a generator of paths in the directory. We can use a path to load an image from disk.\n",
    "The stucture that is often used for storing images is to have subfolders that indicate a label. \n",
    "This is an easy way to create a dataset by a human (just drag and drop the images in the right folder to label them).\n",
    "\n",
    "If the photo is inside the `tulips` subfolder, the class label should be `tulips`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "file = next(paths)\n",
    "img = Image.open(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `iter_valid_paths` function pulls all files, strips the corrects suffixes (we only want images), retrieves the classnames by gathering the names of the subfolders, and returns both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets have a look at the available file types\n",
    "from mads_datasets.settings import FileTypes\n",
    "for ft in FileTypes:\n",
    "    print(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_valid_paths(path: Path, formats: List[FileTypes]) -> Tuple[Iterator, List[str]]:\n",
    "    # gets all files in folder and subfolders\n",
    "    walk = walk_dir(path)\n",
    "\n",
    "    # retrieves foldernames as classnames\n",
    "    class_names = [subdir.name for subdir in path.iterdir() if subdir.is_dir()]\n",
    "\n",
    "    # keeps only specified formats\n",
    "    formats_ = [f.value for f in formats]\n",
    "    paths = (path for path in walk if path.suffix in formats_)\n",
    "    return paths, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formats = [FileTypes.JPG]\n",
    "paths, class_names = iter_valid_paths(\n",
    "    path = image_folder / \"flower_photos\",\n",
    "    formats=formats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(paths), class_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, last, we need the `load_image` function.\n",
    "\n",
    "While there are multiple libraries available to load images (`pyvips`, `PIL`) the functions from `tensorflow` are the fastest for the sequence of tasks:\n",
    "- load image from disk\n",
    "- decode into an array of numbers\n",
    "- resize the image to a fixed size\n",
    "- cast to `numpy` array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgpath = next(paths)\n",
    "newsize = (150, 150)\n",
    "img_ = Image.open(imgpath).resize(newsize, Image.LANCZOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = np.asarray(img_)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(\n",
    "    path: Path, image_size: Tuple[int, int]\n",
    ") -> np.ndarray:\n",
    "    # load file\n",
    "    img_ = Image.open(path).resize(image_size, Image.LANCZOS)\n",
    "    return np.asarray(img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit load_image(file, image_size=(180, 180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = next(paths)\n",
    "img = load_image(file, (180, 180))\n",
    "type(img), img.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at the image we loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(img.astype(np.uint8))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this, we can construct our own data generator, using the design pattern we looked at in lesson 2.\n",
    "\n",
    "- We gather all the paths to files\n",
    "- We shuffle the index_list \n",
    "- For the range of `batchsize`, we use the `index_list[index]` design pattern to gather a random batch\n",
    "- label name is extacted from the subfolder name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can time this, and it is fast enough, considering we have a batchsize of 32; I clocked 2.68ms for a single image, so that would give us about 86ms for just the loading of the 32 images from disk. Depending on things like my cpu temperature, I get around 98ms for a batch. The additional 22ms for resizing, decoding and casting to numpy for 32 images comes down to about 0.7ms per image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.transpose(img, (2, 0, 1))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basis of most `DataSet` objects in libraries is that the `DataSet` has three methods defined:\n",
    "- `__init__` to initialize the object\n",
    "- `__len__` to return the length of the dataset\n",
    "- `__getitem__` to return a batch of data\n",
    "\n",
    "How the lenght of your dataset is defined might vary slightly, but in general it means the number of observations in your dataset (eg the number of images, or texts, etc).\n",
    "The `__getitem__` method is used to return a batch of data. This is the method that is called when you use the `[]` operator on the dataset object.\n",
    "\n",
    "A minimal example would look like this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MyDataSet:\n",
    "    def __init__(self, data: np.ndarray, targets: np.ndarray):\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could make this a bit more specific. Let's say we want to create a template that:\n",
    "- receives a list of files \n",
    "- the files are processed by a function `process_data`\n",
    "- the dataset will be a list, eg a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class BaseDataset:\n",
    "    \"\"\"The main responsibility of the Dataset class is to load the data from disk\n",
    "    and to offer a __len__ method and a __getitem__ method\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, paths: List[Path]) -> None:\n",
    "        self.paths = paths\n",
    "        random.shuffle(self.paths)\n",
    "        self.dataset: list = []\n",
    "        self.process_data()\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple:\n",
    "        return self.dataset[idx]\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        # note we raise an error here. This is a template, and we want to force\n",
    "        # the implementation of this function to be done in the child class\n",
    "        raise NotImplementedError\n",
    "\n",
    "class ImgDataset(BaseDataset):\n",
    "    def __init__(self, paths, class_names, img_size):\n",
    "        self.img_size = img_size\n",
    "        self.class_names = class_names\n",
    "        super().__init__(paths) # this will call the __init__ method of the parent class\n",
    "        # and will shuffle the paths, create .dataset and call process_data\n",
    "\n",
    "    def process_data(self) -> None:\n",
    "        # we dont need to reimplement all the __len__ and __getitem__ methods; they are in the\n",
    "        # parent class. Only thing we need to bother is the process_data method, and some\n",
    "        # additional arguments in the __init__ method\n",
    "        for file in self.paths:\n",
    "            img = load_image(file, self.img_size)\n",
    "            x = np.transpose(img, (2, 0, 1))\n",
    "            y = self.class_names.index(file.parent.name)\n",
    "            self.dataset.append((x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in this implementation, all the images are loaded into memory. Sometimes, that is not possible, and you will need to load the images on the fly. In that case, you should change the `__getitem__` method to load the image from disk, and the process_data method should not load the images, but only do preprocessing that is not dependent on the image itself (if that is necessary at all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, class_names = iter_valid_paths(\n",
    "    path = image_folder / \"flower_photos\",\n",
    "    formats = [FileTypes.JPG],\n",
    ")\n",
    "dataset = ImgDataset([*paths], class_names, img_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = dataset[0]\n",
    "X.shape, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these methods are wrapped together inside the datasetfactory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = flowersfactory.create_dataset()\n",
    "train = datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train[1]\n",
    "x.shape, y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the batch is now a pair of (img, label) tuples. However, we want to untangle a certain amount of them into a list of images and a list of labels.\n",
    "Think of this as unzipping a zipper. Weirdly enough, in python we use the same command for this as we would use to create the pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_processor(batch):\n",
    "    X, Y = zip(*batch)\n",
    "    return np.stack(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = []\n",
    "for i in range(10):\n",
    "    X, y = train[i]\n",
    "    batch.append((X, y))\n",
    "# at this point, we have [(X, y), (X, y), ...]\n",
    "# what we want is: (X, X, ...), (y, y, ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = batch_processor(batch)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see this works as expected: we transformed our list of `[(X, y), (X, y), ...]` into a batched (X, X, X, ...) and (y, y, y, ...) pair.\n",
    "Note the dimensions: we have a batch of 10 images, each image (3, 224, 224) and for the labels we have shape (10,), meaning this is a vector with ten elements.\n",
    "\n",
    "Now, lets combine this in the datastreamer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mads_datasets.base import BaseDatastreamer\n",
    "streamer = BaseDatastreamer(\n",
    "    dataset=train,\n",
    "    batchsize=32,\n",
    "    preprocessor=batch_processor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = streamer.stream()\n",
    "X, y = next(gen)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The streamer will shuffle the index list every epoch, and use that to get the images from the dataset.\n",
    "Our streamer has selected 32 of those pairs and recombined them into a batch of 32 images, sized 150x150, with 3 channels (for colour). The labels are just an array of 32 labels.\n",
    "\n",
    "Our datastreamer will provide us with an endless stream of shuffled batches of images and labels, which we can use to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit X, y = next(gen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep-learning-wM7qE7ca-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "45c41bdaf5373703b03bba2d9bd89c97dc8ee5add9f1112e039ff04603b8e2ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
