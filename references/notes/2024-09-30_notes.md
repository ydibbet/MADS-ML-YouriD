# RNN

We need historical data and how much? 
How much of the future do we want to predict? 
How do we not leak data? 

Timeseries cannot be done using a random train test split -> we have to make sure we dont leak the future into the past (e.g. average price of bitcoin for 50 years = 2mil then you would buy a lot of bitcoin today).

##### What is a state?
Clasroom starts at time t
State could be teaching -> you don't talk in class 
State could be exam -> you don't want noise at all 

State determines what you do with input. 
ReLU causes dying or exploding gradients because of the ReLU form. We instead use tanh because its 1 untill -1

Signal can change states (e.g. "Break time" which then means the state changes). A gate allows for forgetting and retaining memory (a gate remembers these states).

2 options (extremes)
1. Completly ignore new data and remeber past state 
2. Forget past state, new state is now relevant
3. In between, how much keep/update which dimension (20% update, 80% update)

Gate uses Sigmoid activation function instead of tanh. Sigmoid is a value between [0, 1]. Times 1 is remember times 0 is forget.

Check Timeseries data and make sure Train is representative for the test set. Always normalize the data. Use MASE as a scaled error measure. 
